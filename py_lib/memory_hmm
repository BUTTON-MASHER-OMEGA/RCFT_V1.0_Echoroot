# memory_hmm.py

import numpy as np

def update_memory_mass(M_prev, state, valence, t, history, λ):
    # history: list of (time, state, valence)
    M = np.zeros_like(M_prev)
    for (k, s_k, v_k) in history:
        Δt = t - k
        M[s_k] += v_k * np.exp(-λ * Δt)
    return M

def update_transition(A0, M, β):
    A = A0 + β * M[np.newaxis, :]
    return A / A.sum(axis=1, keepdims=True)

import numpy as np

def generate_sequence(T, A, B_means, B_vars, E_means, E_vars):
    states, emissions, valences = [], [], []
    s = np.random.choice(len(A), p=[1/len(A)]*len(A))
    for t in range(T):
        # record
        states.append(s)
        emissions.append(np.random.normal(B_means[s], np.sqrt(B_vars[s])))
        valences.append(np.random.normal(E_means[s], np.sqrt(E_vars[s])))
        # transition
        s = np.random.choice(len(A), p=A[s])
    return np.array(states), np.array(emissions), np.array(valences)

import matplotlib.pyplot as plt

# Example: Memory curve
params = [0.1,0.5,1.0]
gains = [0.02, 0.08, 0.03]  # placeholder
plt.plot(params, gains, marker='o')
plt.xlabel('λ or α')
plt.ylabel('Log‐likelihood gain')
plt.title('Memory Kernel Strength vs Performance')
plt.show()


# Example parameters
A_gt = np.array([[0.8,0.1,0.1],
                 [0.1,0.8,0.1],
                 [0.1,0.1,0.8]])
B_means = [0, 5, 10]
B_vars  = [1, 1, 1]
E_means = [-1, 0, +1]
E_vars  = [0.5, 0.5, 0.5]


# In the HMM‐EM loop:
# 1. Compute M(t) from history
# 2. Build A(t) via update_transition
# 3. Run E‐step / M‐step with time‐varying A(t)
