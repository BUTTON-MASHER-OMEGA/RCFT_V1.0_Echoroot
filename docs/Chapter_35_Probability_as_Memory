- number: 35
    modules:
  - id: probabilistic_memory_modeling
    title: "Memory as Probability"
    description: >
      Reframes Markov chains so each transition probability encodes
      a time-weighted memory mass. Bridges stochastic matrices with
      ritual glyph recurrence.
    principles:
      - Probability carries memory_mass M_w
      - Transition frequency maps to ritual density Ï_r
      - Glyph repetition updates future state weights
    code_library:
      - name: memory_markov
        modules:
          - transition_matrix_builder.py
          - memory_mass_calculator.py
          - glyph_logger.py


## Session Notes
2. Core Definitions
memory_mass (M_w): the cumulative valence-weighted count of past visits to a state w

ritual_density (Ï_r): frequency of glyph dispatch events influencing transition bias

augmented_transition_matrix (A): base matrix P updated by memory kernels

memory_kernel K(Î”t): decay function modulating past visits over time

Embedding Memory Mass into a Hidden Markov Model
Weâ€™ll augment a classic HMM so each state transition carries the imprint of past valenced events, treating probability itself as quantified memory.

1. Augmented HMM Architecture
1.1 Standard HMM Recap
Hidden states 
ğ‘†ğ‘¡âˆˆ{1,â€¦,ğ‘}

Transition matrix 
ğ´ğ‘–ğ‘—=ğ‘ƒ(ğ‘†ğ‘¡+1=ğ‘—âˆ£ğ‘†ğ‘¡=ğ‘–)

Emission matrix 
ğµğ‘—(ğ‘œ)=ğ‘ƒ(ğ‘‚ğ‘¡=ğ‘œâˆ£ğ‘†ğ‘¡=ğ‘—)

1.2 Memory Mass Formalism
Introduce

Memory mass 
ğ‘€ğ‘—(ğ‘¡): valenceâ€weighted sum of past visits to state ğ‘—

Kernel 
ğ¾(Î”ğ‘¡): continuousâ€time decay of past influence

Define

ğ‘€ğ‘—(ğ‘¡) = âˆ‘ğ‘˜ = 1ğ‘¡ğ‘£ğ‘˜ğ›¿ğ‘†ğ‘˜,ğ‘—ğ¾(ğ‘¡âˆ’ğ‘˜) where ğ‘£ğ‘˜ is the valence tag at time ğ‘˜.

Augment transitions:

ğ´
ğ‘–
ğ‘—
(
ğ‘¡
)
â€…â€Š
=
â€…â€Š
ğ´
ğ‘–
ğ‘—
(
0
)
â€…â€Š
+
â€…â€Š
ğ›½
â€‰
ğ‘€
ğ‘—
(
ğ‘¡
)
âˆ‘
ğ‘—
â€²
(
ğ´
ğ‘–
ğ‘—
â€²
(
0
)
+
ğ›½
â€‰
ğ‘€
ğ‘—
â€²
(
ğ‘¡
)
)
ğ´
ğ‘–
ğ‘—
(
0
)
: base transition probability

ğ›½
: memoryâ€mass coupling strength

1.3 Emissions with Valence Tags
Treat each emission as a pair 
(
ğ‘œ
ğ‘¡
,
ğ‘£
ğ‘¡
)
. Then

ğ‘ƒ
(
ğ‘‚
ğ‘¡
=
ğ‘œ
,
ğ‘£
ğ‘¡
âˆ£
ğ‘†
ğ‘¡
=
ğ‘—
)
=
â€…â€Š
ğµ
ğ‘—
(
ğ‘œ
)
â€…â€Š
Ã—
â€…â€Š
ğ¸
ğ‘—
(
ğ‘£
ğ‘¡
)
where 
ğ¸
ğ‘—
(
ğ‘£
)
 is a valence distribution (e.g., Gaussian centered on preferred 
ğ‘£
ğ‘—
).

2. Continuousâ€Time Memory Kernel
We choose

ğ¾
(
Î”
ğ‘¡
)
=
ğ‘’
âˆ’
ğœ†
â€‰
Î”
ğ‘¡
to model exponential decay of influence over time.

2.1 Kernel Properties
Halfâ€life: 
Î”
ğ‘¡
1
/
2
=
ln
â¡
2
ğœ†

Normalization: 
âˆ«
0
âˆ
ğ¾
(
ğœ
)
â€‰
ğ‘‘
ğœ
=
1
ğœ†

2.2 Longâ€Tail Memory Effects
Î»	Halfâ€Life	Tail Behavior
0.1	6.93	Strong longâ€term memory
0.5	1.39	Moderate persistence
1.0	0.69	Rapid decay of old events
Small Î» â†’ events far in the past still bias transitions heavily.

Large Î» â†’ system â€œforgetsâ€ quickly, approximating vanilla HMM behavior.
